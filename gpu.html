<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>GPU-servers &mdash; HPC user-guides 2024 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="_static/css/extra.css" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Containers (Singularity &amp; Docker)" href="singularity.html" />
    <link rel="prev" title="Visualization" href="visualization.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #E4067E" >

          
          
          <a href="index.html" class="icon icon-home">
            HPC user-guides
              <img src="_static/TalTech_Gradient-200px.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="lumi.html">LUMI</a></li>
<li class="toctree-l1"><a class="reference internal" href="cloud.html">Quickstart: Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart: Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="learning.html">Courses and introductions</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">Module environment (lmod)</a></li>
<li class="toctree-l1"><a class="reference internal" href="software.html">Software packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="mpi.html">Available MPI versions (and comparison)</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance.html">Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiling.html">Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization.html">Visualization</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">GPU-servers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#hardware">Hardware</a></li>
<li class="toctree-l2"><a class="reference internal" href="#login-and-localstorage">Login and localstorage</a></li>
<li class="toctree-l2"><a class="reference internal" href="#running-jobs">Running jobs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#software-and-modules">Software and modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#from-ai-lab"><em>From AI lab</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="#software-that-supports-gpus"><em>Software that supports GPUs</em></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#gpu-libraries-and-tools">GPU libraries and tools</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#nvidia-cuda-11"><em>Nvidia CUDA 11</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="#offloading-compilers"><em>Offloading Compilers</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="#openmp-offloading"><em>OpenMP offloading</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#nvidia-hpc-sdk"><em>Nvidia HPC SDK</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#openacc-offloading"><em>OpenACC offloading</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1"><em>Nvidia HPC SDK</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="#gcc-needs-testing"><em>GCC (needs testing)</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hip-upcoming"><em>HIP (upcoming)</em></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="singularity.html">Containers (Singularity &amp; Docker)</a></li>
<li class="toctree-l1"><a class="reference internal" href="acknowledgement.html">Acknowledgement</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #E4067E" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">HPC user-guides</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">GPU-servers</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/gpu.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <p><span style="color:orange">only partially changed to rocky yet</span></p>
<section id="gpu-servers">
<h1>GPU-servers<a class="headerlink" href="#gpu-servers" title="Permalink to this heading"></a></h1>
<p><span style="color:blue">job submission from “base”</span></p>
<p><span style="color:red">The AI-lab “Illukas” modules will NOT work on the cluster due to different OS</span></p>
<br>
<br>
<br>
<hr style="margin-right: 0px; margin-bottom: 4px; margin-left: 0px; margin-top: -24px; border:2px solid  #d9d9d9 "></hr>
<hr style="margin: 4px 0px; border:1px solid  #d9d9d9 "></hr><section id="hardware">
<h2>Hardware<a class="headerlink" href="#hardware" title="Permalink to this heading"></a></h2>
<hr class="docutils" />
 <div class="simple1"> <b>amp1</b> <ul class="simple">
<li><p>CPU: 2x AMD EPYC 7742 64core</p></li>
<li><p>RAM: 1 TB</p></li>
<li><p>GPUs: 8x A100 Nvidia 40GB</p></li>
<li><p>OS: Rocky8</p></li>
</ul>
 </div> 
 <br> <div class="simple1"> <b>amp2</b> <ul class="simple">
<li><p>CPU: 2x AMD EPYC 7713 64core (3rd gen EPYC, Zen3)</p></li>
<li><p>RAM: 2 TB</p></li>
<li><p>GPUs: 8x A100 Nvidia 80GB</p></li>
<li><p>OS: Rocky8</p></li>
</ul>
 </div> 
 <br> <div class="simple1"> <b>ada[1,2]</b> <ul class="simple">
<li><p>CPU: 2x AMD EPYC 9354 32core (4th gen EPYC, Zen4)</p></li>
<li><p>RAM: 1.5 TB</p></li>
<li><p>GPUs: 2x L40 Nvidia 48GB</p></li>
<li><p>avx512</p></li>
<li><p>OS: Rocky8</p></li>
</ul>
 </div> 
 <br><br>
<br>
<hr style="margin-right: 0px; margin-bottom: 4px; margin-left: 0px; margin-top: -24px; border:2px solid  #d9d9d9 "></hr>
<hr style="margin: 4px 0px; border:1px solid  #d9d9d9 "></hr></section>
<section id="login-and-localstorage">
<h2>Login and localstorage<a class="headerlink" href="#login-and-localstorage" title="Permalink to this heading"></a></h2>
<hr class="docutils" />
<p>No direct login, jobs are submitted from “base”, use <code class="docutils literal notranslate"><span class="pre">srun</span> <span class="pre">-p</span> <span class="pre">gpu</span> <span class="pre">--gres=gpu:L40</span> <span class="pre">--pty</span> <span class="pre">bash</span></code></p>
<p>amp[1,2] have <code class="docutils literal notranslate"><span class="pre">/localstorage</span></code> a 10 TB NVMe partition for fast data access. Data in directory has a longer sstorage duration than data in the 4 TB <code class="docutils literal notranslate"><span class="pre">/tmp</span></code> (<code class="docutils literal notranslate"><span class="pre">/state/partition1</span></code> is the same as <code class="docutils literal notranslate"><span class="pre">/tmp</span></code>)</p>
<br>
<hr style="margin-right: 0px; margin-bottom: 4px; margin-left: 0px; margin-top: -24px; border:2px solid  #d9d9d9 "></hr>
<hr style="margin: 4px 0px; border:1px solid  #d9d9d9 "></hr></section>
<section id="running-jobs">
<h2>Running jobs<a class="headerlink" href="#running-jobs" title="Permalink to this heading"></a></h2>
<hr class="docutils" />
<p>Jobs need to be submitted using <code class="docutils literal notranslate"><span class="pre">srun</span></code> or <code class="docutils literal notranslate"><span class="pre">sbatch</span></code>, do not run jobs outside the batch system.</p>
<p>Interactive jobs are started using <code class="docutils literal notranslate"><span class="pre">srun</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">srun</span> <span class="o">-</span><span class="n">p</span> <span class="n">gpu</span> <span class="o">-</span><span class="n">t</span> <span class="mi">1</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span> <span class="o">--</span><span class="n">pty</span> <span class="n">bash</span>
</pre></div>
</div>
<p>GPUs have to be reserved/requested with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">srun</span> <span class="o">-</span><span class="n">p</span> <span class="n">gpu</span> <span class="o">--</span><span class="n">gres</span><span class="o">=</span><span class="n">gpu</span><span class="p">:</span><span class="n">A100</span><span class="p">:</span><span class="mi">1</span> <span class="o">-</span><span class="n">t</span> <span class="mi">1</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span> <span class="o">--</span><span class="n">pty</span> <span class="n">bash</span>
</pre></div>
</div>
<p>all nodes with GPUs are in the same partition (<code class="docutils literal notranslate"><span class="pre">-p</span> <span class="pre">gpu</span></code>, but also in <code class="docutils literal notranslate"><span class="pre">short</span></code>, which has higher priority, but shorter time-limit) so jobs that do not have specific requirements can run on any of the nodes. If you need a specific type, e.g. for testing performance or because of memory requirements:</p>
<ul class="simple">
<li><p>it is possible to request the feature “A100-40” (for the 40GB A100s), “A100-80” (for the 80GB A100s):** <code class="docutils literal notranslate"><span class="pre">--gres=gpu:A100:1</span> <span class="pre">--constraint=A100-80</span></code> or <code class="docutils literal notranslate"><span class="pre">--gres=gpu:1</span> <span class="pre">--constraint=A100-40</span></code></p></li>
<li><p>it is also possible to request the”compute capability, e.g. cc80 (for A100) or cc89 (for L40) using <code class="docutils literal notranslate"><span class="pre">--gres=gpu:1</span> <span class="pre">--constraint=cc89</span></code> = <code class="docutils literal notranslate"><span class="pre">--gres=gpu:L40:1</span></code></p></li>
<li><p>another option is to request the job to run on a specific node, using the <code class="docutils literal notranslate"><span class="pre">-w</span></code> switch (e.g. <code class="docutils literal notranslate"><span class="pre">srun</span> <span class="pre">-p</span> <span class="pre">gpu</span> <span class="pre">-w</span> <span class="pre">amp1</span> <span class="pre">--gres=gpu:A100:1</span> <span class="pre">...</span> </code>)</p></li>
</ul>
<p>You can see which GPUs have been assigned to your job using <code class="docutils literal notranslate"><span class="pre">echo</span> <span class="pre">$CUDA_VISIBLE_DEVICES</span></code>, <strong>the CUDA-deviceID in your programs always start with “0” (no matter which physical GPU was assigned to you by SLURM)</strong>.</p>
<br>
<hr style="margin-right: 0px; margin-bottom: 4px; margin-left: 0px; margin-top: -24px; border:2px solid  #d9d9d9 "></hr>
<hr style="margin: 4px 0px; border:1px solid  #d9d9d9 "></hr></section>
<section id="software-and-modules">
<h2>Software and modules<a class="headerlink" href="#software-and-modules" title="Permalink to this heading"></a></h2>
<hr class="docutils" />
<p>same modules as on all nodes, i.e. the rocky8 and rocky8-spack modules.</p>
<section id="from-ai-lab">
<h3><em>From AI lab</em><a class="headerlink" href="#from-ai-lab" title="Permalink to this heading"></a></h3>
<p>will not work due to different OS</p>
</section>
<section id="software-that-supports-gpus">
<h3><em>Software that supports GPUs</em><a class="headerlink" href="#software-that-supports-gpus" title="Permalink to this heading"></a></h3>
<ul class="simple">
<li><p>JupyterLab, see page on <a class="reference internal" href="data-analysis/jupyter.html"><span class="doc">JupyterLab</span></a></p></li>
<li><p>Gaussian, see page on <a class="reference internal" href="chemistry/gaussian.html"><span class="doc">Gaussian</span></a></p></li>
<li><p>cp2k</p></li>
<li><p>StarCCM+</p></li>
<li><p>Julia</p></li>
<li><p>Chapel</p></li>
<li><p>Singularity (apptainer), see page on <a class="reference internal" href="singularity.html"><span class="doc">Singularity</span></a></p></li>
</ul>
<br>
<br>
<hr style="margin-right: 0px; margin-bottom: 4px; margin-left: 0px; margin-top: -24px; border:2px solid  #d9d9d9 "></hr>
<hr style="margin: 4px 0px; border:1px solid  #d9d9d9 "></hr><p><span style="color:orange">only partially changed to rocky yet</span></p>
</section>
</section>
<section id="gpu-libraries-and-tools">
<h2>GPU libraries and tools<a class="headerlink" href="#gpu-libraries-and-tools" title="Permalink to this heading"></a></h2>
<hr class="docutils" />
<p>The GPUs installed are Nvidia A100 with compute capability 80, compatible with CUDA 11. However, when developing own software, be aware of vendor lockin, CUDA is only available for Nvidia GPUs and does not work on AMD GPUs. Some new supercomputers (LUMI (CSC), El Capitan (LLNL), Frontier (ORNL)) are using AMD, and some plan the Intel “Ponte Vecchio” GPU (Aurora (ANL), SuperMUC-NG (LRZ)). To be future-proof, portable methods like OpenACC/OpenMP are recommended.</p>
<p>Porting to AMD/HIP for LUMI: <a class="reference external" href="https://www.lumi-supercomputer.eu/preparing-codes-for-lumi-converting-cuda-applications-to-hip/">https://www.lumi-supercomputer.eu/preparing-codes-for-lumi-converting-cuda-applications-to-hip/</a></p>
<section id="nvidia-cuda-11">
<h3><em>Nvidia CUDA 11</em><a class="headerlink" href="#nvidia-cuda-11" title="Permalink to this heading"></a></h3>
<p>Again, beware of the vendor lockin.</p>
<p>To compile CUDA code, use the Nvidia compiler wrapper:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nvcc</span>
</pre></div>
</div>
</section>
<section id="offloading-compilers">
<h3><em>Offloading Compilers</em><a class="headerlink" href="#offloading-compilers" title="Permalink to this heading"></a></h3>
<ul class="simple">
<li><p>PGI (Nvidia HPC-SDK) supports OpenACC and OpenMP offloading to Nvidia GPUs</p></li>
<li><p>GCC-10.3.0</p></li>
<li><p>GCC-11.2.0 with NVPTX supports GPU-offloading using OpenMP and OpenACC pragmas</p></li>
<li><p>LLVM-13.0.0 (Clang/Flang) with NVPTX supports GPU-offloading using OpenMP pragmas</p></li>
</ul>
<br><p>See also: <a class="reference external" href="https://lumi-supercomputer.eu/offloading-code-with-compiler-directives/">https://lumi-supercomputer.eu/offloading-code-with-compiler-directives/</a></p>
</section>
<section id="openmp-offloading">
<h3><em>OpenMP offloading</em><a class="headerlink" href="#openmp-offloading" title="Permalink to this heading"></a></h3>
<p>Since version 4.0 supports offloading to accelerators. It can be utilized by GCC, LLVM (C/Flang) and Nvidia HPC-SDK (former PGI compilers).</p>
<ul class="simple">
<li><p>GCC-10.3.0</p></li>
<li><p>GCC-11.2.0 with NVPTX supports GPU-offloading using OpenMP and OpenACC pragmas</p></li>
<li><p>LLVM-13.0.0 (Clang/Flang) with NVPTX supports GPU-offloading using OpenMP pragmas</p></li>
<li><p>AOMP</p></li>
</ul>
<br><p>List of compiler support for OpenMP: <a class="reference external" href="https://www.openmp.org/resources/openmp-compilers-tools/">https://www.openmp.org/resources/openmp-compilers-tools/</a></p>
<p>Current recommendation: use Clang or GCC or AOMP</p>
<section id="nvidia-hpc-sdk">
<h4><em>Nvidia HPC SDK</em><a class="headerlink" href="#nvidia-hpc-sdk" title="Permalink to this heading"></a></h4>
<p>Compile option <code class="docutils literal notranslate"><span class="pre">-⁠mp</span></code> for CPU-OpenMP or <code class="docutils literal notranslate"><span class="pre">-mp=gpu</span></code> for GPU-OpenMP-offloading.</p>
<p>The table below summarizes useful compiler flags to compile you OpenMP code with offloading.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th></th>
<th>NVC/NVFortran</th>
<th>Clang/Cray/AMD</th>
<th>GCC/GFortran</th>
</tr>
</thead>
<tbody>
<tr>
<td>OpenMP flag</td>
<td>-mp</td>
<td>-fopenmp</td>
<td>-fopenmp -foffload=<target></td>
</tr>
<tr>
<td>Offload flag</td>
<td>-mp=gpu</td>
<td>-fopenmp-targets=<target></td>
<td>-foffload=<target></td>
</tr>
<tr>
<td>Target NVIDIA</td>
<td>default</td>
<td>nvptx64-nvidia-cuda</td>
<td>nvptx-none</td>
</tr>
<tr>
<td>Target AMD</td>
<td>n/a</td>
<td>amdgcn-amd-amdhsa</td>
<td>amdgcn-amdhsa</td>
</tr>
<tr>
<td>GPU Architecture</td>
<td>-gpu=<cc></td>
<td>-Xopenmp-target -march=<arch></td>
<td>-foffload=”-march=<arch></td>
</tr>
</tbody>
</table></section>
</section>
<section id="openacc-offloading">
<h3><em>OpenACC offloading</em><a class="headerlink" href="#openacc-offloading" title="Permalink to this heading"></a></h3>
<p>OpenACC is a portable compiler directive based approach to GPU computing. It can be utilized by GCC, (LLVM (C/Flang)) and Nvidia HPC-SDK (former PGI compilers).</p>
<p>Current recommendation: use HPC-SDK</p>
<section id="id1">
<h4><em>Nvidia HPC SDK</em><a class="headerlink" href="#id1" title="Permalink to this heading"></a></h4>
<p>Installed are versions 21.2, 21.5 and 21.9 (2021). These come with modulefiles, to use them, enable the the directory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">rocky8</span><span class="o">-</span><span class="n">spack</span>
</pre></div>
</div>
<p>then load the module you want to use, e.g.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">nvhpc</span>
</pre></div>
</div>
<p>The HPC SDK also comes with a profiler, to identify regions that would benefit most from GPU acceleration.</p>
<p>OpenACC is based on compiler pragmas enabling an incremental approach to parallelism (you never break the sequential program), it can be used for CPUs (multicore) and GPUs (tesla).</p>
<p>Compiling an OpenACC program with the Nvidia compiler:
get accelerator information</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pgaccelinfo</span>
</pre></div>
</div>
<p>compile for multicore (C and Fortran commands)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pgcc</span> <span class="o">-</span><span class="n">fast</span> <span class="o">-</span><span class="n">ta</span><span class="o">=</span><span class="n">multicore</span> <span class="o">-</span><span class="n">Minfo</span><span class="o">=</span><span class="n">accel</span> <span class="o">-</span><span class="n">I</span><span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">nvidia</span><span class="o">/</span><span class="n">hpc_sdk</span><span class="o">/</span><span class="n">Linux_x86_64</span><span class="o">/</span><span class="mf">21.5</span><span class="o">/</span><span class="n">cuda</span><span class="o">/</span><span class="mf">11.3</span><span class="o">/</span><span class="n">targets</span><span class="o">/</span><span class="n">x86_64</span><span class="o">-</span><span class="n">linux</span><span class="o">/</span><span class="n">include</span><span class="o">/</span>  <span class="o">-</span><span class="n">o</span> <span class="n">laplace</span> <span class="n">jacobi</span><span class="o">.</span><span class="n">c</span> <span class="n">laplace2d</span><span class="o">.</span><span class="n">c</span>
<span class="n">pgfortran</span> <span class="o">-</span><span class="n">fast</span> <span class="o">-</span><span class="n">ta</span><span class="o">=</span><span class="n">multicore</span>  <span class="o">-</span><span class="n">Minfo</span><span class="o">=</span><span class="n">accel</span> <span class="o">-</span><span class="n">I</span><span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">nvidia</span><span class="o">/</span><span class="n">hpc_sdk</span><span class="o">/</span><span class="n">Linux_x86_64</span><span class="o">/</span><span class="mf">21.5</span><span class="o">/</span><span class="n">cuda</span><span class="o">/</span><span class="mf">11.3</span><span class="o">/</span><span class="n">targets</span><span class="o">/</span><span class="n">x86_64</span><span class="o">-</span><span class="n">linux</span><span class="o">/</span><span class="n">include</span><span class="o">/</span> <span class="o">-</span><span class="n">o</span> <span class="n">laplace_multicore</span> <span class="n">laplace2d</span><span class="o">.</span><span class="n">f90</span> <span class="n">jacobi</span><span class="o">.</span><span class="n">f90</span>
</pre></div>
</div>
<p>compile for GPU (C and Fortran commands)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pgcc</span> <span class="o">-</span><span class="n">fast</span> <span class="o">-</span><span class="n">ta</span><span class="o">=</span><span class="n">tesla</span> <span class="o">-</span><span class="n">Minfo</span><span class="o">=</span><span class="n">accel</span>  <span class="o">-</span><span class="n">I</span><span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">nvidia</span><span class="o">/</span><span class="n">hpc_sdk</span><span class="o">/</span><span class="n">Linux_x86_64</span><span class="o">/</span><span class="mf">21.5</span><span class="o">/</span><span class="n">cuda</span><span class="o">/</span><span class="mf">11.3</span><span class="o">/</span><span class="n">targets</span><span class="o">/</span><span class="n">x86_64</span><span class="o">-</span><span class="n">linux</span><span class="o">/</span><span class="n">include</span><span class="o">/</span> <span class="o">-</span><span class="n">o</span> <span class="n">laplace_gpu</span> <span class="n">jacobi</span><span class="o">.</span><span class="n">c</span> <span class="n">laplace2d</span><span class="o">.</span><span class="n">c</span>
<span class="n">pgfortran</span> <span class="o">-</span><span class="n">fast</span> <span class="o">-</span><span class="n">ta</span><span class="o">=</span><span class="n">tesla</span><span class="p">,</span><span class="n">managed</span> <span class="o">-</span><span class="n">Minfo</span><span class="o">=</span><span class="n">accel</span> <span class="o">-</span><span class="n">I</span><span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">nvidia</span><span class="o">/</span><span class="n">hpc_sdk</span><span class="o">/</span><span class="n">Linux_x86_64</span><span class="o">/</span><span class="mf">21.5</span><span class="o">/</span><span class="n">cuda</span><span class="o">/</span><span class="mf">11.3</span><span class="o">/</span><span class="n">targets</span><span class="o">/</span><span class="n">x86_64</span><span class="o">-</span><span class="n">linux</span><span class="o">/</span><span class="n">include</span><span class="o">/</span> <span class="o">-</span><span class="n">o</span> <span class="n">laplace_gpu</span> <span class="n">laplace2d</span><span class="o">.</span><span class="n">f90</span> <span class="n">jacobi</span><span class="o">.</span><span class="n">f90</span>
</pre></div>
</div>
<p>Profiling:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nsys</span> <span class="n">profile</span> <span class="o">-</span><span class="n">t</span> <span class="n">nvtx</span> <span class="o">--</span><span class="n">stats</span><span class="o">=</span><span class="n">true</span> <span class="o">--</span><span class="n">force</span><span class="o">-</span><span class="n">overwrite</span> <span class="n">true</span> <span class="o">-</span><span class="n">o</span> <span class="n">laplace</span> <span class="o">./</span><span class="n">laplace</span>
<span class="n">nsys</span> <span class="n">profile</span> <span class="o">-</span><span class="n">t</span> <span class="n">openacc</span> <span class="o">--</span><span class="n">stats</span><span class="o">=</span><span class="n">true</span> <span class="o">--</span><span class="n">force</span><span class="o">-</span><span class="n">overwrite</span> <span class="n">true</span> <span class="o">-</span><span class="n">o</span> <span class="n">laplace_data_clauses</span> <span class="o">./</span><span class="n">laplace_data_clauses</span> <span class="mi">1024</span> <span class="mi">1024</span>
</pre></div>
</div>
<p>Analysing the profile using CLI:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nsys</span> <span class="n">stat</span> <span class="n">s</span> <span class="n">laplace</span><span class="o">.</span><span class="n">qdrep</span>
</pre></div>
</div>
<p>using the GUI:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nsys</span><span class="o">-</span><span class="n">ui</span>
</pre></div>
</div>
<p>then load the <code class="docutils literal notranslate"><span class="pre">.qdrep</span></code> file.</p>
</section>
<section id="gcc-needs-testing">
<h4><em>GCC (needs testing)</em><a class="headerlink" href="#gcc-needs-testing" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>GCC-10.3.0</p></li>
<li><p>GCC-11.2.0 with NVPTX supports GPU-offloading using OpenMP and OpenACC pragmas</p></li>
</ul>
<br></section>
</section>
<section id="hip-upcoming">
<h3><em>HIP (upcoming)</em><a class="headerlink" href="#hip-upcoming" title="Permalink to this heading"></a></h3>
<p>For porting code to AMD-Instinct based LUMI, the AMD HIP SDK will be installed.</p>
<br>
<hr style="margin-right: 0px; margin-bottom: 4px; margin-left: 0px; margin-top: -24px; border:2px solid  #d9d9d9 "></hr>
<hr style="margin: 4px 0px; border:1px solid  #d9d9d9 "></hr><br>
<br></section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="visualization.html" class="btn btn-neutral float-left" title="Visualization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="singularity.html" class="btn btn-neutral float-right" title="Containers (Singularity &amp; Docker)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright COPYRIGHT.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>